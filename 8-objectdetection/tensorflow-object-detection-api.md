---
description: "Building Custom Object Detection Step by Step (under development \U0001F469â€\U0001F52C)"
---

# ğŸ¤– TensorFlow Object Detection API

## ğŸš© Development Pipeline

* Environment Preparation
* Image acquiring
* Image Organization
* Model Selecting
* Model Configuration
* Training
* Evaluation

## ğŸ‘©â€ğŸ’» Environment Preparation

### ğŸ”¸ Environment Info

| ğŸ’» Platform | ğŸ·ï¸ Version |
| :--- | :--- |
| Python version | 3.7 |
| TensorFlow version | 1.15 |

### ğŸ¥¦ Conda env Setting

#### ğŸ”® Create new env

ğŸ’» Open cmd and run:

```bash
# conda create -n <ENV_NAME> python=<REQUIRED_VERSION>
conda create -n tf1 python=3.7
```

#### â–¶ï¸ Activate the new env

```bash
# conda activate <ENV_NAME>
conda activate tf1
```

### ğŸ”½ Install Packages

#### ğŸš€  Installing TensorFlow

{% tabs %}
{% tab title="ğŸš€ GPU" %}
```bash
conda install tensorflow-gpu=1.15 
```
{% endtab %}

{% tab title="ğŸš™ CPU" %}
```bash
conda install tensorflow=1.15 
```
{% endtab %}
{% endtabs %}

#### ğŸ“¦ Installing other packages

```bash
conda install pillow Cython lxml jupyter matplotlib
```

```bash
conda install -c anaconda protobuf
```

### ğŸ¤– Downloading models repository

#### ğŸ¤¸â€â™€ï¸ Cloning from GitHub

* A repository that contains required utils for training and evaluation process
* Open CMD and run in `E` disk and run:

```bash
# note that every time you open CMD you have 
# to activate your env again by running: 
# E:\>conda activate tf1
(tf1) E:\>git clone https://github.com/tensorflow/models.git
(tf1) E:\>cd models/research
```

{% hint style="warning" %}
ğŸ§ I assume that you are running your commands under `E` disk, 
{% endhint %}

#### ğŸ”ƒ Compiling Protobufs

```bash
(tf1) E:\models\research>for /f %i in ('dir /b object_detection\protos\*.proto') ^do protoc object_detection\protos\%i --python_out=.
```

#### ğŸ“¦ Compiling Packages

```bash
(tf1) E:\models\research>python setup.py build
(tf1) E:\models\research>python setup.py install
```

#### ğŸš© Setting Python Path

```bash
(tf1) E:\models\research>set PYTHONPATH=E:\models\research;E:\models\research\slim
```

### ğŸ‘©â€ğŸ”¬ Installation Test

#### ğŸ’» Command

```bash
(tf1) E:\models\research>python object_detection/builders/model_builder_test.py
```

#### ğŸ‰ Expected Output

```bash
Ran 17 tests in 0.833s

OK (skipped=1)
```

## ğŸ–¼ï¸ Image Acquiring 

#### ğŸ‘®â€â™€ï¸ Directory Structure

* ğŸ—ï¸ I suppose that you created a structure like:

```graphql
E:
|___ models
|___ demo
      |___ annotations
      |___ images
      |___ inference
      |___ OIDv4_ToolKit
      |___ OpenImagesTool
      |___ pre_trainded_model
      |___ scripts
      |___ training
```

| ğŸ“‚ Folder | ğŸ“ƒ Description |
| :--- | :--- |
| ğŸ¤– `models` | the repo [**here**](https://github.com/tensorflow/models)\*\*\*\* |
| ğŸ“„ `annotations` | will contain generated `.csv` and `.tfrecord` files |
| ğŸ–¼ï¸ `images` | will contain image data set |
| â–¶ï¸ `inference` | will contain exported models after training |
| ğŸ”½ `OIDv4_ToolKit` | the repo [**here**](https://github.com/EscVM/OIDv4_ToolKit) \(_OpenImages_ Downloader\) |
| ğŸ‘©â€ğŸ”§ `OpenImagesTool` | the repo [**here**](https://github.com/asmaamirkhan/OpenImagesTool) \(_OpenImages_ Organizer\) |
| ğŸ‘©â€ğŸ«`pre_trained_model`  | will contain files of _TensorFlow_ model that we will retrain |
| ğŸ‘©â€ğŸ’» `scripts`  | will contain scripts that we will use for pre-processing and training processes |
| ğŸš´â€â™€ï¸ `training`  | will contain generated check points during training |

#### ğŸš€ OpenImages Dataset

* ğŸ•µï¸â€â™€ï¸ You can get images in various methods 
* ğŸ‘©â€ğŸ« I will show process of organizing OpenImages data set
* ğŸ—ƒï¸ OpenImages is a huge data set contains annotated images of 600 objects
* ğŸ” You can explore images by categories from [**here**](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&r=false&c=%2Fm%2F0420v5) 

{% embed url="https://storage.googleapis.com/openimages/web/index.html" %}

#### ğŸ¨ Downloading By Category

* OIDv4\_Toolkit is a tool that we can use to download OpenImages dataset by category and by set \(test, train, validation\)
* 
ğŸ’» To clone and build the project, open CMD and run:

```bash
(tf1) E:\pre_trainded_model>git clone https://github.com/EscVM/OIDv4_ToolKit.git
(tf1) E:\pre_trainded_model>cd OIDv4_ToolKit
(tf1) E:\pre_trainded_model\OIDv4_ToolKit>pip install -r requirements.txt
```

â¬ To start downloading by category:

```bash
# python main.py downloader --classes <OBJECT_LIST> --type_csv <TYPE>
# TYPE: all | test | train | validation 
(tf1) E:\pre_trainded_model\OIDv4_ToolKit>python main.py downloader --classes Apple Orange --type_csv validation
```

{% hint style="warning" %}
ğŸ‘®â€â™€ï¸ If object name consists of 2 parts write it with `_, e.g.` Bell\_pepper
{% endhint %}



